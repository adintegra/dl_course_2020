{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple forward pass\n",
    "\n",
    "In this notebook you will do a simple forward pass for a neural network with and without hidden layers. You will use the sigmoid function to calculate the probability if a banknote is fake or not. We have to input features of the banknote.  \n",
    "You will use random values for the weight initialization.  \n",
    "\n",
    "**Dataset:** You work with a banknote data set and classification task. We have 2 features.\n",
    "\n",
    "* x1: skewness of wavelet transformed image  \n",
    "* x2: entropy of wavelet transformed image  \n",
    "\n",
    "Don't bother too much how these features exactely came from.\n",
    "\n",
    "**The goal is to classify each banknote to either \"real\" (Y=0) or \"fake\" (Y=1).**\n",
    "\n",
    "\n",
    "**Content:**\n",
    "* calculate the forward pass of the neural network without hidden layer by hand, with matrix multiplication and keras\n",
    "* visualize the learned decision boundary in a 2D plot\n",
    "* calculate the forward pass of the neural network with one hidden layer (8 nodes) with matrix multiplication and keras\n",
    "* visualize the learned decision boundary in a 2D plot\n",
    "* compare the decision boundaries of the two models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just assume x1 and x2\n",
    "x1 = 1\n",
    "x2 = 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just assume w1 and w2 and b1\n",
    "w1 = 0.3\n",
    "w2 = 0.1\n",
    "b  = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwad pass by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1*w1+x2*w2)+b ## output before the activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid((x1*w1+x2*w2)+b) ## output after the sigmoid activation\n",
    "                         ## probability for the banknote to be fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwad pass with matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[x1,x2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=np.array([[w1],[w2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(X,W)+b  ## output before the activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(np.matmul(X,W)+b) ## output after the sigmoid activation\n",
    "                          ## probability for the banknote to be fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwad pass in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()                                        # starts the definition of the network\n",
    "model.add(Dense(1, batch_input_shape=(None, 2),             # adds a new layer to the network with a single neuron  \n",
    "                activation='sigmoid'))                      # The input is a tensor of size (batch_size, 2), \n",
    "                                                            # since we don’t specify the Batch Size now, we use None as a placeholder\n",
    "                                                            # chooses the activation function ‘sigmoid’\n",
    "# Definition of the optimizer\n",
    "sgd = optimizers.SGD(lr=0.15)                               # Defining the stochastic gradient descent optimizer\n",
    "\n",
    "# compile model                                             # compile model, which ends the definition of the model \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,                                # using the stochastic gradient descent optimizer\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([W,np.array([b])])                        ## set the weights of the model to w1 w2 and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### funtion to plot the decision boundary\n",
    "\n",
    "def plotModel(X, model, t):\n",
    "    # define a grid for the 2D feature space\n",
    "    # predict at each grid point the probability for class 1\n",
    "\n",
    "    x1list = np.linspace(-10, 10, 12) # Define 100 points on the x-axis\n",
    "    x2list = np.linspace(-10, 10, 12) # Define 100 points on the x-axis\n",
    "    X1_grid, X2_grid = np.meshgrid(x1list, x2list)\n",
    "\n",
    "    # model.predict for respective value x1 and x2 \n",
    "    p = np.array([model.predict(np.reshape(np.array([l1,l2]),(1,2))) for l1,l2 in zip(np.ravel(X1_grid), np.ravel(X2_grid))])\n",
    "    print(p.shape)\n",
    "    if len(p.shape) == 3 and p.shape[2]==2:\n",
    "        p = p[:,:,1] # pick p for class 1 if there are more than 2 classes\n",
    "    p = np.reshape(p,X1_grid.shape)\n",
    "\n",
    "    # visualize the predicted probabilities in the 2D feature space\n",
    "    # once without and once with the data points used for fitting\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.subplot(1,2,(1))\n",
    "    cp = plt.contourf(X1_grid, X2_grid, p,cmap='RdBu_r')\n",
    "    plt.colorbar(cp)\n",
    "    plt.title(t)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the decision boundary\n",
    "\n",
    "plotModel(X, model, 'fcnn separation without hidden layer') \n",
    "plt.scatter(X[0][0],X[0][1],c=\"black\",s=50)\n",
    "#plt.vlines(X[0][0],-10,10)\n",
    "#plt.hlines(X[0][1],-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "Play around with the values for x1 and x2 and check if the position at the decision boundary\n",
    "matches the predicted probability\n",
    "How does the decision boundary look? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwad pass with hidden layer (matrix multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the same values for x1 and x2 and random normal values for the weights\n",
    "X=np.array([[x1,x2]])\n",
    "np.random.seed(22)\n",
    "W1=np.reshape((np.random.normal(0,1,16)),(2,8))\n",
    "np.random.seed(22)\n",
    "b1=np.reshape((np.random.normal(0,1,8)),(8,))\n",
    "np.random.seed(22)\n",
    "W2=np.reshape((np.random.normal(0,1,8)),(8,1))\n",
    "np.random.seed(22)\n",
    "b2=np.reshape((np.random.normal(0,1,1)),(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(W2.shape)\n",
    "print(b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden=sigmoid(np.matmul(X,W1)+b1)\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_out=sigmoid(np.matmul(hidden,W2)+b2)\n",
    "p_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwad pass with hidden layer (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()                                        \n",
    "model.add(Dense(8, batch_input_shape=(None, 2),activation='sigmoid'))                      \n",
    "model.add(Dense(1, activation='sigmoid'))                      \n",
    "\n",
    "# Definition of the optimizer\n",
    "sgd = optimizers.SGD(lr=0.15)                               # Defining the stochastic gradient descent optimizer\n",
    "\n",
    "# compile model                                              \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,                                \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([W1,b1,W2,b2]) ## set the weights of the model to W1, b1, W2 and b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the decision boundary\n",
    "\n",
    "plotModel(X, model, 'fcnn separation with hidden layer') \n",
    "plt.scatter(X[0][0],X[0][1],c=\"black\",s=50)\n",
    "#plt.vlines(X[0][0],-10,10)\n",
    "#plt.hlines(X[0][1],-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "Play around with the values for x1 and x2 and check if the position at the decision boundary\n",
    "matches the predicted probability\n",
    "How does the decision boundary look? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
